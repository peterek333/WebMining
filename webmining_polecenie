- 3 serwisy - wykop (przekopywanie), facebook/twitter (api), jakaś inna opcja dowolna
- loguje sie do aplikacji (uwierzytelniane)
- wpisuje haslo jakie obserwowac
- system, ktory przesyla notyfikacje (kolejka -> signal/websocket)
+ zapytania offline (np. z wyrazeniem regularnym) - czyli szuka po bazie
+ wizualizowanie danych (np. sentyment wykres co bylo, a co nie) na statycznej stronie
+ docker
KOLEJKA - RabbitMQ (najprostszy), redis

- obsluzyc robot.txt


1. Przeszukuję po nagłówkach tematów czy jeszcze zawartości?
Na wykopie mógłbym użyć wyszukiwarki i zbierać tematy. Dla przypadku z całą zawartością tematu wymagałoby to przetworzenia całej strony.

2. Nie będzie problemu z komunikowaniem się aplikacji w oddzielnych kontenerach dockera?

3. Python 2.7 vs 3.5?
4. Jaką baze danych wybrać?


Założenia:
- 2 serwisy: wykop.pl (wyszukiwarka?) oraz twitter API
- pobieranie wyników co 60 sekund
- porównanie z bazą danych czy jest coś nowego
- jeśli jest wysłanie do kolejki wygenerowanie notyfikacji (mail?)


Kolejność pracy:
0. Założyć konta do API wykop/twitter
1. Skonfigurować dockery (proste pobranie strony Pythonem)


RabbitMQ Python
https://www.rabbitmq.com/tutorials/tutorial-one-python.html
